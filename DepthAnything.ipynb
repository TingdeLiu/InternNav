{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl' # or 'vits', 'vitb', 'vitg'\n",
    "\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "raw_img = cv2.imread('your/image/path')\n",
    "depth = model.infer_image(raw_img) # HxW raw depth map in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd315ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf8b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
